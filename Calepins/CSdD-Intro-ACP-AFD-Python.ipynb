{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://websites.isae-supaero.fr/certificat/\" ><img src=\"https://websites.isae-supaero.fr/IMG/gif/computer-science.gif\" style=\"float:left; max-width: 120px; display: inline\" alt=\"Toulouse Tech\"/> </a>\n",
    "\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:right; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>\n",
    "\n",
    "# [Certificat Science des Données](https://github.com/Certificat-sciences-des-donnees-bigdata) [Module de Sensibilisation](https://github.com/Certificat-sciences-des-donnees-bigdata/Module-sensibilisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Exploration Multidimensionnelle]()\n",
    "# [Anayse en Composantes Principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf) et [Analyse Factorielle Discriminante](http://wikistat.fr/pdf/st-m-explo-afd.pdf) \n",
    "**Résumé**: Ce calepin introduit l'exploration statistique en utilisant la librairie `scikit-learn` par des exemples de mise en oeuvre de l'[ACP](http://wikistat.fr/pdf/st-m-explo-acp.pdf) et de l'[AFD]() sur des données \"jouet\". Il développe ensuite deux applications de l'ACP, sur des images élémentaires de caractères et enfin sur des données économiques sous une la forme particulière d'un cube ou tableau à trois indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 `Scikit-learn` *vs.*  R\n",
    "L'objectif de ce tutoriel est d'introduire l'exploration de données multidimensionnelles  en utilisantla librairie `scikit-learn` de Python. Seule l'utilisation directe des fonctions d'exploration est abordée. Se pose rapidement une question: quand utiliser `scikit-learn` de Python plutôt que R plus complet pour certaines fonctionnalités et plus simple d'emploi?\n",
    "\n",
    "Le choix repose sur les points suivants:\n",
    "- **Attention** cette librairie manipule des objets de classe `array` de `numpy` *chargés en mémoire* et donc de taille limitée par la RAM de l'ordinateur; de façon analogue R charge en RAM des objets de type `data.frame`.\n",
    "- **Attention** toujours, `scikit-learn` ne reconnaît pas (ou pas encore ?) la classe `DataFrame` de `pandas`; `scikit-learn` utilise la classe `array` de `numpy`. C'est un problème pour la gestion de variables qualitatives complexes. Une variable binaire est simplement remplacée par un codage $(0,1)$ mais, en présence de plusieurs modalités, traiter celles-ci comme des entiers n'a pas de sens statistique et remplacer une variable qualitative par l'ensemble des indicatrices (*dummy variables* $(0,1)$) de ses modalités  complique l'interprétation statistique. \n",
    "- Les implémentations en Python de certains algorithmes dans `scikit-learn` sont aussi efficaces (*e.g.* $k$-means), voire beaucoup plus efficaces pour des données volumineuses car utilisent implicitement les capacités de parallélisation.\n",
    "- R offre beaucoup plus de possibilités pour une exploration, des recherches et comparaisons, des interprétations mais les capacités de parallélisation de Python sont nettement plus performantes. Plus précisément, l'introduction de nouvelles librairies n'est pas ou peu contraintes dans R, alors que celle de nouvelles méthodes dans `scikit-learn` se fait sous l'autorité d'un groupe qui en contrôle la pertinence et l'efficacité. \n",
    "\n",
    "En conséquences:\n",
    "- Préférer R et ses libraires si la **présentation graphique** des résultats et leur **interprétation** est prioritaire.\n",
    "- Pour l'emploi de méthodes pas disponibles en Python.\n",
    "- Préférer Python et `scikit-learn` pour mettre au point une chaîne de traitements (*pipe line*) opérationnelle de l'extraction à une analyse privilégiant la prévision brute à l'interprétation et pour des données quantitatives ou rendues quantitatives (\"vectorisation\" de corpus de textes).\n",
    "\n",
    "### 1.2 Fonctions de `scikit-learn`\n",
    "La communauté qui développe cette librairie est très active, elle évolue rapidement.  Ne pas hésiter à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) pour des compléments. Voici une sélection de ses principales fonctionnalités.\n",
    "- Transformations (standardisation, discrétisation binaire, regroupement de modalités, imputations rudimentaires de données manquantes) , \"vectorisation\" de corpus de textes (encodage, catalogue, Tf-idf), images.\n",
    "- Exploration: ACP, classification non supervisée (mélanges gaussiens, propagation d'affinité, ascendante hiérarchique, SOM,...). Une fonction est ajoutée pour l'Analyse des Correspondances.\n",
    "- Modélisation et apprentissage, voir le dépôt correspondant.\n",
    "\n",
    "\n",
    "### 1.3 ACP avec `scikit-learn`\n",
    "L'objectif est d'illustrer la mise en oeuvre de l'[analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf). Consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) et ses nombreux [exemples](http://scikit-learn.org/stable/auto_examples/index.html) pour plus de détails sur l'utilisation de `scikit-learn`. \n",
    "\n",
    "La librairie `scikit-learn` a principalement été conçue en vue de l'analyse de signaux. Aussi, de nombreuses options de l'ACP ne sont pas disponibles, notamment les graphiques usuels (biplot, cercle des corrélations...). En revanche des résultats sont liés à la version probabiliste de l'ACP sous hypothèse d'une distribution gaussienne multidimensionnelle des données. \n",
    "\n",
    "**Attention**, l'ACP est évidemment centrée mais pas réduite. L'option n'est pas prévue et les variables doivent être réduites (fonction `sklearn.preprocessing.scale`) avant si c'est nécessaire. L'attribut `transform` désigne les composantes principales, sous-entendu: transformation par réduction de la dimension; `n_components` fixe le nombre de composantes retenues, par défaut toutes; l'attribut `components_` contient les `n_components` vecteurs propres mais non normalisés, c'est-à-dire de norme carrée la valeur propre associée, et donc à utiliser pour représenter les variables.\n",
    "\n",
    "D'autres versions d'analyse en composantes principales sont proposées dans `Scikit-learn`: *kernel PCA, sparse PCA, ICA*...\n",
    "\n",
    "\n",
    "Plusieurs jeux de données élémentaires sont utilisés dont un \"jouet\" afin de bien comprendre les sorties proposées par la fonction disponible.  L'autre ensemble de données est un problème classique et simplifié de [reconnaissance de caractères](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) qui est inclus dans la librairie `scikit-learn`.\n",
    "\n",
    "# <FONT COLOR=\"Red\">Première partie: Exploration</font>\n",
    "\n",
    "## 2.  ACP de données \"jouet\"\n",
    "Les données sont celles de l'exemple du document pdf et aussi de l'[introduction à l'ACP](http://wikistat.fr/pdf/st-l-des-multi): les notes en maths, français, physique et anglais de 9 lycéens virtuels. Les mêmes données sont analysées avec R dans un autre [tutoriel](https://github.com/wikistat/Exploration/blob/master/TutosRudim/Cal1-R-SVDtoACP.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:04.116009Z",
     "start_time": "2019-10-28T07:58:03.374924Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Construire la matrice de notes\n",
    "note=[[6,6,5,5.5],[8,8,8,8],[6,7,11,9.5],[14.5,14.5,15.5,15],\n",
    "   [14,14,12,12.5],[11,10,5.5,7],[5.5,7,14,11.5],[13,12.5,8.5,9.5],\n",
    "   [9,9.5,12.5,12]]\n",
    "dat=pd.DataFrame(note,index=[\"jean\",\"alai\",\"anni\",\"moni\",\"didi\",\"andr\",\"pier\",\"brig\",\"evel\"],\n",
    "   columns=[\"Math\",\"Phys\",\"Fran\",\"Angl\"])\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:04.318134Z",
     "start_time": "2019-10-28T07:58:04.118255Z"
    }
   },
   "outputs": [],
   "source": [
    "dat.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice des nuages de points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:05.487748Z",
     "start_time": "2019-10-28T07:58:04.320598Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(dat, figsize=(5, 5), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la nature des liaisons entre les variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.051098Z",
     "start_time": "2019-10-28T07:58:05.492316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importation des fonctions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice des variances-covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.066034Z",
     "start_time": "2019-10-28T07:58:06.053114Z"
    }
   },
   "outputs": [],
   "source": [
    "dat.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice des corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.079079Z",
     "start_time": "2019-10-28T07:58:06.068380Z"
    }
   },
   "outputs": [],
   "source": [
    "dat.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Résumer la structure de corrélation entre les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Valeurs propres de l'ACP non réduite\n",
    "Contrairement aux habitudes de beaucoup de logiciels, l'ACP de `scikit-learn` n'est pas *réduite* par défaut. Par ailleurs, le diviseur de la formule de calcul de la variance est celui d'une estimation sans biais: $(n-1)$ au lieu de $n$.\n",
    "\n",
    "Calcul des valeurs propres ou variances des composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.098100Z",
     "start_time": "2019-10-28T07:58:06.082647Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "valPropres=pca.fit(dat).explained_variance_\n",
    "print(valPropres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrouver les valeurs propres du cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.109410Z",
     "start_time": "2019-10-28T07:58:06.101664Z"
    }
   },
   "outputs": [],
   "source": [
    "valPropres*8/9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Vecteurs propres de l'ACP non réduite\n",
    "\n",
    "Les vecteurs propres sont aussi les coefficients des combinaisons linéaires des variables permettant de définir les variables principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.126755Z",
     "start_time": "2019-10-28T07:58:06.113109Z"
    }
   },
   "outputs": [],
   "source": [
    "pca.components_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Composantes principales de l'ACP non réduite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.141243Z",
     "start_time": "2019-10-28T07:58:06.129249Z"
    }
   },
   "outputs": [],
   "source": [
    "C = pca.fit(dat).transform(dat)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution des composantes principales. \n",
    "\n",
    "**Q** Quel choix de dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.388174Z",
     "start_time": "2019-10-28T07:58:06.145551Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.boxplot(C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les autres résultats (contributions, cossinus carrés, corrélations variables facteurs...) et surtout les graphes (éboulis, plans factoriels...) sont à construire car aucune fonction n'est disponible comme dans le package `FactoMineR` de R. C'est partièlement fait dans avec l'ACP des jeux de données suivants (section 4 et 5) et complété (*biplot*) dans les calepins plus détaillés des autres cas d'usage disponibles sur sur le dépôt [`github/wikistat`](https://github.com/wikistat/).\n",
    "\n",
    "### 2.4 Représentation des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.587244Z",
     "start_time": "2019-10-28T07:58:06.389947Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for i, j, nom in zip(C[:,0], C[:,1], dat.index):\n",
    "    plt.text(i, j, nom, fontsize=16)\n",
    "plt.axis((-10,12,-6,8))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** le signe d'un vectreur propre n'est pas pas déterminé car c'est une direction ou sous-espace qui est \"propre\" pour une matrice. En fonction de l'algorithme ou logiciel utilisé, le vecteur peut être orienté dans un sens ou dans l'autre mais c'est bien la même direction qui est définie. Cela n'a aucune influence sur l'interprétation de ces résultats.\n",
    "\n",
    "### 2.5 Graphe des variables\n",
    "Calcul des coordonnées et réprésentation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.777455Z",
     "start_time": "2019-10-28T07:58:06.589447Z"
    }
   },
   "outputs": [],
   "source": [
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, dat.columns):\n",
    "    plt.text(i, j, nom, fontsize=16)\n",
    "    plt.arrow(0,0,i,j,color='black')\n",
    "plt.axis((-4,4,-4,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le cercle des corrélations n'est pas tracé car les variables ne sont pas réduites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 AFD de données \"jouet\"\n",
    "L'objectif de cet exemple sur des données très simples est de montrer l'intérêt d'une AFD par rapport à une ACP lorsque des groupes ou classes des individus sont connues *a priori*.\n",
    "\n",
    "### 3.1 Lecture des données\n",
    "Les données sont issues de l'observation de 6 variables, des dimensions d'ailes, élitres, antennes, pattes de 3 classes d'insectes. Il s'agit donc de vérifier graphiquement la bonne capacité de ces variables à distinguer ou discriminer ces trois classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:06.846210Z",
     "start_time": "2019-10-28T07:58:06.779712Z"
    }
   },
   "outputs": [],
   "source": [
    "insect=pd.read_csv(\"https://www.math.univ-toulouse.fr/~besse/Wikistat/Data/lubisch.txt\",sep='\\s+',header=0)\n",
    "insect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ACP \n",
    "**Q** Quel est le graphique ci-dessous? Comment choisir le nombre de composantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:07.107664Z",
     "start_time": "2019-10-28T07:58:06.848092Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X=scale(insect[[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\"]])\n",
    "Y=insect[\"Y\"]\n",
    "C = pca.fit(X).transform(X)\n",
    "plt.boxplot(C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphique des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:07.524543Z",
     "start_time": "2019-10-28T07:58:07.109701Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i, j, nom in zip(C[:,0],C[:,1], Y):\n",
    "    plt.scatter(i, j, color=nom)\n",
    "plt.axis((-5,7,-4,4))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter la forme des trois nuages de points, la déjà bonne séparation des classes.\n",
    "\n",
    "#### Graphique des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:07.704360Z",
     "start_time": "2019-10-28T07:58:07.526103Z"
    }
   },
   "outputs": [],
   "source": [
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, insect.columns):\n",
    "    plt.text(i, j, nom, fontsize=16)\n",
    "    plt.arrow(0,0,i,j,color='black')\n",
    "plt.axis((-1.2,1.2,-1.2,1.2))\n",
    "# cercle\n",
    "c=plt.Circle((0,0), radius=1, color='gray', fill=False)\n",
    "ax.add_patch(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter la structure de corrélation des variables, la qualité de représentation.\n",
    "\n",
    "### 3.3 AFD\n",
    "\n",
    "\n",
    "L'AFD est l'ACP des barycentres des classes avec la métrique de Mahalanobis dans l'espace des individus.\n",
    "\n",
    "**Q** Comment cette métrique est-elle définie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:07.720087Z",
     "start_time": "2019-10-28T07:58:07.706893Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "method = LinearDiscriminantAnalysis()\n",
    "lda=method.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que devient la forme des nuages? A quoi cela est-il dû? Commenter la séparation des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.126466Z",
     "start_time": "2019-10-28T07:58:07.722121Z"
    }
   },
   "outputs": [],
   "source": [
    "Clda=lda.transform(X)\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, j, nom in zip(Clda[:,0],Clda[:,1], Y):\n",
    "    plt.scatter(i, j, color=nom)\n",
    "plt.axis((-8,7,-4,6))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Compléments: Exploration</font> de données plus complexes\n",
    "Les deux exemples qui suivents proposent des applications de l'ACP à d'autres jeux de données afin de montrer les capacités de cette méthode d'exploration multidimensionnelle. Ce sont des compléments intéressants mais pas indispensables à la bonne compréhension de la suite du cours.\n",
    "\n",
    "## 4 ACP des données \"Caractères\"\n",
    "\n",
    "\n",
    "Il s'agit d'explorer les données issues de la pixellisation de tracés de caractères dont les procédés d'obtention et prétraitement sont décrits sur le [site de l'UCI](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) (Lichman, 2013). Les chiffres ont été saisies sur des tablettes à l'intérieur de cadres de résolution $500\\times 500$. Des procédures de normalisation,  ré-échantillonnage spatial puis de lissage ont été appliquées. Chaque caractère apparaît finalement discrétisé sous la forme d'une matrice $8\\times 8$ de pixels à 16 niveaux de gris et identifié par un label. Les données sont archivées sous la forme d'une matrice ou tableau à trois indices. Elles sont également archivées après vectorisation des images sous la forme d'une matrice à $p=64$ colonnes.\n",
    "\n",
    "L'étude du même type de données, mais nettement plus complexes (MNIST): 60 000 caractères représentés par des images de 784 pixels (26 $\\times$ 26) fait l'objet d'un autre calepin.\n",
    "\n",
    "### 4.1 Prise en main des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.311905Z",
     "start_time": "2019-10-28T07:58:08.128531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importations \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "# les données présentes dans la librairie\n",
    "digits = datasets.load_digits()\n",
    "# Contenu et mode d'obtention\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.322281Z",
     "start_time": "2019-10-28T07:58:08.314023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.334660Z",
     "start_time": "2019-10-28T07:58:08.326549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sous forme d'un cube d'images 1797 x 8x8\n",
    "print(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.348392Z",
     "start_time": "2019-10-28T07:58:08.341402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sous forme d'une matrice 1797 x 64\n",
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.360393Z",
     "start_time": "2019-10-28T07:58:08.351971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label réel de chaque caractère\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un aperçu des empilements des images à décrire puis ensuite en principe à discriminer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.677827Z",
     "start_time": "2019-10-28T07:58:08.364721Z"
    }
   },
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, \n",
    "   digits.target))\n",
    "for index, (image, label) in  enumerate(images_and_labels[:8]):\n",
    "     plt.subplot(2, 4, index + 1)\n",
    "     plt.axis('off')\n",
    "     plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "     plt.title('Chiffres: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:08.903766Z",
     "start_time": "2019-10-28T07:58:08.680766Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X=digits.data\n",
    "y=digits.target\n",
    "target_name=[0,1,2,3,4,5,6,7,8,9]\n",
    "# définition de la commande\n",
    "pca = PCA()\n",
    "# Estimation, calcul des composantes principales\n",
    "C = pca.fit(X).transform(X)\n",
    "# Décroissance de la variance expliquée\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagramme boîte des premières composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:09.396995Z",
     "start_time": "2019-10-28T07:58:08.906236Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.boxplot(C[:,0:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle dimension retenir en principe?\n",
    "\n",
    "Représentation des caractères dans le premier plan principal. \n",
    "\n",
    "La représentation des variables (pixels) et le *biplot* n'ont pas grand intérêt pour ces données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:09.747746Z",
     "start_time": "2019-10-28T07:58:09.399596Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(C[:,0], C[:,1], c=y, label=target_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le même graphique avec une légende mais moins de couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.059775Z",
     "start_time": "2019-10-28T07:58:09.751372Z"
    }
   },
   "outputs": [],
   "source": [
    "# attention aux indentations\n",
    "plt.figure()\n",
    "for c, i, target_name in zip(\"rgbcmykrgb\",[0,1,2,3,4,5,6,7,8,9], target_name):\n",
    "       plt.scatter(C[y == i,0], C[y == i,1], c=c, label=target_name)\n",
    "plt.legend()\n",
    "plt.title(\"ACP Digits\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphique en trois dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.263906Z",
     "start_time": "2019-10-28T07:58:10.061765Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "ax.scatter(C[:, 0], C[:, 1], C[:, 2], c=y, cmap=plt.cm.Paired)\n",
    "ax.set_title(\"ACP: trois premieres composantes\")\n",
    "ax.set_xlabel(\"Comp1\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"Comp2\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"Comp3\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  Données \"cubiques\" de l'OCDE\n",
    "###  5.1 Introduction\n",
    "#### Objectif\n",
    "L'objectif de cette section  est l'exploration de données socio-économiques plus complexes. La principale spécificité de ces données est de se présenter  sous la forme d'un cube de données ou tableau à trois entrées: le numéro de ligne, le numéro de variable et l'année d'observation de cette variable. Après une description classique, la mise en oeuvre de l'analyse en composantes principales avec python nécessite un effort particulier afin de produire les graphes adaptés à la structure particulière des données. \n",
    "\n",
    "#### Les données\n",
    "Les données sont issues de l'Observatoire de l'OCDE.  Pour chaque pays membre et pour chacune des années  1975, 1977, 1979, 1981, on connaît les valeurs prises par les  variables suivantes qui sont toutes des \\emph{taux}~:\n",
    "- Taux brut de natalité, \n",
    "- Taux de chômage, \n",
    "- Pourcentage d'actifs dans le secteur primaire, \n",
    "- Pourcentage d'actifs dans le secteur secondaire, \n",
    "- produit intérieur brut (par habitant), \n",
    "- Formation brute de capital fixe (par habitant), \n",
    "- Hausse des prix, \n",
    "- Recettes courantes  (par habitant), \n",
    "- Mortalité infantile, \n",
    "- Consommation de protéines animales  (par habitant), \n",
    "- Consommation d'énergie  (par habitant).\n",
    "\n",
    "Elles sont disponibles dans le fichier: `ocdeR.dat`.\n",
    "\n",
    "Les mêmes variables sont donc observées, sur les mêmes pays ou individus à quatre dates différentes. Plusieurs stratégies d'analyse sont possibles (tableau moyen, tableaux concaténés, meilleur compromis ou double ACP). La plus adaptée pour ces données est de considérer les observations des variables pour chacun des individus:  pays $\\times$ années. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.275742Z",
     "start_time": "2019-10-28T07:58:10.265760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importation des principals librairies et \n",
    "# Affichage des graphiques dans le notebook\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2 Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.336693Z",
     "start_time": "2019-10-28T07:58:10.278121Z"
    }
   },
   "outputs": [],
   "source": [
    "ocde=pd.read_csv(\"https://www.math.univ-toulouse.fr/~besse/Wikistat/Data/ocde.txt\",sep='\\s+',header=0)\n",
    "ocde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  Statistiques élémentaires\n",
    "Consulter rapidement ces résultats; Que dire à propos de la symétrie des distributions, de leur normalité, des valeurs atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.346154Z",
     "start_time": "2019-10-28T07:58:10.339198Z"
    }
   },
   "outputs": [],
   "source": [
    "ocde.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:10.529923Z",
     "start_time": "2019-10-28T07:58:10.349015Z"
    }
   },
   "outputs": [],
   "source": [
    "ocde[\"CNRJ\"].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:15.151813Z",
     "start_time": "2019-10-28T07:58:10.532120Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(ocde, alpha=0.2, figsize=(15, 15), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le graphique ci-dessous? Que représentent les blocs dagonaux? Que dire des structures de corrélation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 [Analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf)\n",
    "Chaque pays étant observé 4 fois, la principale difficulté technique est de faire apparaître cette structure chronologique dans les graphique afin d'illustrer la dynamique économique de la période considérée.\n",
    "\n",
    "**Q** Justifier la nécessité de réduire.\n",
    "\n",
    "**Q** Pourqoi toutes les variables sont des taux?\n",
    "\n",
    "#### Choix de dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:15.293904Z",
     "start_time": "2019-10-28T07:58:15.153221Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "# réduction\n",
    "ocdeS=scale(ocde)\n",
    "pca = PCA()\n",
    "cpOcde = pca.fit_transform(ocdeS)\n",
    "# Eboulis\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:15.520823Z",
     "start_time": "2019-10-28T07:58:15.297700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.boxplot(cpOcde)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le graphe ci-dessus. Que dire de la première composante? Quelle dimension choisir?\n",
    "\n",
    "#### Représentation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:15.663335Z",
     "start_time": "2019-10-28T07:58:15.526010Z"
    }
   },
   "outputs": [],
   "source": [
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, ocde.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0,0,i,j,color='black')\n",
    "plt.axis((-1.2,1.2,-1.2,1.2))\n",
    "# cercle\n",
    "c=plt.Circle((0,0), radius=1, color='gray', fill=False)\n",
    "ax.add_patch(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Interpréter chacun des deux premiers axes.\n",
    "\n",
    "**Exo** représenter le plan (2,3) et interpréter le 3ème axe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation basique des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:15.924397Z",
     "start_time": "2019-10-28T07:58:15.665197Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i, j, nom in zip(cpOcde[:,0], cpOcde[:,1], ocde.index):\n",
    "#    color = int(i/4)\n",
    "    plt.text(i, j, nom ,color=\"blue\")\n",
    "plt.axis((-5,7,-4,4))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation adaptée à ces données\n",
    "La structure particulière des données nécessite un graphique adapté. Ceci est en fait le **principal objectif** d'une *bonne exploration des données*: trouver la **représentation graphique** qui permet d'en comprendre toute la structure en une seule vue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:58:16.341932Z",
     "start_time": "2019-10-28T07:58:15.926162Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "comp_0 = 0\n",
    "comp_1 = 1\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for i,k in enumerate(np.arange(0,cpOcde.shape[0],4)):\n",
    "    country =ocde.index[k]\n",
    "    xs = cpOcde[k:k+4,comp_0]\n",
    "    ys = cpOcde[k:k+4, comp_1]\n",
    "    ax.plot(xs,ys, color=cmap(i), marker=\".\", markersize=15)\n",
    "    txt = ax.text(xs[-4], ys[-4], country, horizontalalignment=\"left\", verticalalignment=\"top\",\n",
    "            color=cmap(i), fontweight=\"bold\", fontsize=15)\n",
    "    # Add black line around text\n",
    "    #txt.set_path_effects([PathEffects.withStroke(linewidth=1, foreground='black')])\n",
    "    ax.set_xlabel(\"PC%d\" %comp_0, fontsize=20)\n",
    "    ax.set_ylabel(\"PC%d\" %comp_1, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Analyser les évolutions des économies des différents pays. Les remplacer dans la période considérée. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
