{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:right; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>\n",
    "\n",
    "# [Certificat Science des Données](https://github.com/Certificat-sciences-des-donnees-bigdata) [Module de Sensibilisation](https://github.com/Certificat-sciences-des-donnees-bigdata/Module-sensibilisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Introduction à l'Apprentissage Statistique]()\n",
    "\n",
    "# Adaptation Statistique d'un Modèle de Prévision du Pic d'Ozone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**: Exploration puis modélisation de données climatiques en utilisant Python et la librairie [Scikit-learn](http://scikit-learn.org/stable/#). L'objectif est de prévoir pour le lendemain un possible dépassement d'un seuil de concentration en ozone à partir d'une prévision déterministe sur un maillage grossier et de variables climatiques locales. Estimation par différentes méthodes: régression [logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [k plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf), [arbre de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [agrégation de modèle](http://wikistat.fr/pdf/st-m-app-agreg.pdf), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf). Comparaison des [erreurs de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) sur un échantillon test puis des courbes ROC. Itération sur plusieurs échantillons tests pour analyser la distribution de l'erreur de prévision. \n",
    "\n",
    " <FONT COLOR=\"Green\">\n",
    "**Ce tutoriel est divisé en trois parties: les deux du cours  du module Sensibilisation plus des compléments. **\n",
    "1. Exploration\n",
    "2. Apprentissage et prévision\n",
    "3. Compléments correspondant au module Immersion\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "L'objectif, sur ces données, est d'améliorer la prévision déterministe (MOCAGE), calculée par les services de MétéoFrance,  de la concentration d'ozone dans certaines stations de prélèvement.  Il s'agit d'un problème dit d'*adaptation statistique* ou post-traitement d'une prévision locale de modèles à trop grande échelle en s'aidant d'autre variables également gérées par MétéoFrance, mais à plus petite échelle (température, force du vent...). \n",
    "\n",
    "La question posée reste: quelle est la meilleure stratégie pour prévoir l'occurrence d'un pic de pollution. \n",
    "\n",
    "Comme avec R différentes méthodes sont testées : régression logistique, k plus proches voisins, arbre de décision, random forest, SVM. Les réseaux de neurones nécessitent la version 0.18 de Scikit-learn. De façon générale on suppose que l'utilisatuer dispose d'une installation python à jour. Le calepin a été testé avec la version 3 de python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Green\">Première partie: Exploration</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prise en compte des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont été extraites et mises en forme par le service concerné de Météo France. Elles sont décrites par les variables suivantes:\n",
    "\n",
    "\n",
    "* **O3obs** La concentration d'ozone effectivement observée le lendemain à 17h locales correspondant souvent au maximum de pollution observée ; (CIBLE)\n",
    "* **jour** Le type de jour ; férié (1) ou pas (0) ;\n",
    "* **MOCAGE** Prévision de cette pollution obtenue par un modèle déterministe de mécanique des fluides (équation de Navier et Stockes);\n",
    "* **TEMPE** Température prévue par MétéoFrance pour le lendemain 17h ;\n",
    "* **RMH2O** Rapport d'humidité ;\n",
    "* **NO2** Concentration en dioxyde d'azote ;\n",
    "* **NO** Concentration en monoxyde d'azote ;\n",
    "* **station** Lieu de l'observation : Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques ;\n",
    "* **VentMOD** Force du vent ;\n",
    "* **VentANG** Orientation du vent. \n",
    "\n",
    "Ce sont des données \"propres\", sans trous, bien codées et de petites tailles. Elles présentent avant tout un caractère pédagogique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.157459Z",
     "start_time": "2019-10-28T10:26:44.527762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des données présentes dans le dépôt: \"./Data/\"\n",
    "df = pd.read_csv(\n",
    "    \"https://www.math.univ-toulouse.fr/~besse/Wikistat/Data/depSeuil.dat\", \n",
    "    sep = \",\",\n",
    "    header = 0,\n",
    "    dtype = {\"JOUR\": \"category\", \"STATION\": \"category\"}\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.225504Z",
     "start_time": "2019-10-28T10:26:45.175102Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même si les données ne présentent pas de défauts particuliers, une étude exploratoire préliminaire est indispensable afin de s'assurer le leur bonne cohérence, proposer d'éventuelles transformations et analyser les structures de corrélations ou plus généralement de liaisons entre les variables, de groupes des individus ou observations. Il est aussi intéressant d'identifier les observations anormales (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Unidimensionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.399580Z",
     "start_time": "2019-10-28T10:26:45.227460Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.640318Z",
     "start_time": "2019-10-28T10:26:45.401441Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"O3obs\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.799624Z",
     "start_time": "2019-10-28T10:26:45.642808Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"MOCAGE\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.811774Z",
     "start_time": "2019-10-28T10:26:45.801297Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"SRMH2O\"] = np.sqrt(df[\"RMH2O\"])\n",
    "df[\"LNO2\"]   = np.log(df[\"NO2\"])\n",
    "df[\"LNO\"]    = np.log(df[\"NO\"])\n",
    "\n",
    "df = df.drop([\"RMH2O\", \"NO2\", \"NO\"], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice:** Visualisez les variables `[SRMH2O, LNO2, LNO]` avec un histogramme et commentez la structure de ces variables que nous avons créées. Quelle est l'impact de cette transformation pour un modèle linéaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les variables explicatives initiales `[SRMH2O, LNO2, LNO]` et construire ci-dessous la variable `dépassement de seuil` pour obtenir le fichier qui sera effectivement utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:45.834753Z",
     "start_time": "2019-10-28T10:26:45.814648Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"dep_seuil\"] = df[\"O3obs\"] > 150\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exploration multidimensionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:50.631823Z",
     "start_time": "2019-10-28T10:26:45.837900Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"O3obs\", \"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    df[columns], \n",
    "    alpha   = 0.2, \n",
    "    figsize = (15, 15), \n",
    "    diagonal = 'kde'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Commenter les relations entre les variables prises 2 à 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 [Analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:51.346704Z",
     "start_time": "2019-10-28T10:26:50.634029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Réduction des variables\n",
    "columns = [\"O3obs\", \"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]\n",
    "\n",
    "X = scale(df[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes permettent de réaliser une analyse en composantes principales sur les seules variables quantitatives. Par ailleurs la variable à modéliser (O3obs, concentration observée) n'est pas utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:51.622235Z",
     "start_time": "2019-10-28T10:26:51.349400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des composantes principales:\n",
    "pca = PCA()\n",
    "C = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance expliquée / composantes principales:\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:51.875124Z",
     "start_time": "2019-10-28T10:26:51.624324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution des composantes principales:\n",
    "plt.boxplot(C[:,0:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter ces résultats: quel choix de la dimension? \n",
    "\n",
    "**Q** Présence de valeurs atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:54.368982Z",
     "start_time": "2019-10-28T10:26:51.878218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Repésentation des individus:\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "for i, j, nom in zip(C[:,0], C[:,1], df[\"dep_seuil\"]):\n",
    "    color = \"red\" if nom  else \"blue\"\n",
    "    plt.plot(i, j, \"o\", color = color)\n",
    "    \n",
    "plt.axis((-4,6,-4,6))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:54.604794Z",
     "start_time": "2019-10-28T10:26:54.370744Z"
    }
   },
   "outputs": [],
   "source": [
    "## coordonnées et représentation des variables\n",
    "coord1 = pca.components_[0] * np.sqrt(pca.explained_variance_[0])\n",
    "coord2 = pca.components_[1] * np.sqrt(pca.explained_variance_[1])\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i, j, nom in zip(coord1, coord2, columns):\n",
    "    \n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0, 0, i, j, color = 'black')\n",
    "    \n",
    "plt.axis((-1.2, 1.2, -1.2, 1.2))\n",
    "\n",
    "# cercle\n",
    "c = plt.Circle((0,0), radius = 1, color = 'gray', fill = False)\n",
    "ax.add_patch(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Quel est la structure de corrélation des variables?\n",
    "\n",
    "**Question:** Une séparatrice linéaire (hyperplan) semble-t-elle adaptée à l'identification des classes?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce n'est pas utile ici mais une classification non supervisée est facile à obtenir à titre illustratif, par exemple en 3 classes, par l'algorithme k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster  import  KMeans\n",
    "from  sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:54.771771Z",
     "start_time": "2019-10-28T10:26:54.606861Z"
    }
   },
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=3)\n",
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes attribuées aux différentes observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = clustering.labels_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.063297Z",
     "start_time": "2019-10-28T10:26:54.775089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Repésentation des individus dans les coordonnées de l'ACP.\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(C[:,0], C[:,1], c = classes) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Green\">Deuxième partie: Apprentissage et Prévision</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modélisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche  d'une meilleure méthode de prévision suit généralement le protocole suivant dont la première étape est déja réalisée.\n",
    "\n",
    "1. Etape descriptive préliminaire uni et multidimensionnelle visant à repérer les incohérences, les variables non significatives ou de distribution exotique, les individus non concernés ou atypiques... et à étudier les structures des données. Ce peut être aussi la longue étape de construction de variables, attributs ou *features* spécifiques des données. \n",
    "\n",
    "2. Procéder à un tirage aléatoire d'un échantillon *test* qui ne sera utilisé que lors de la *dernière étape* de comparaison des méthodes.\n",
    "\n",
    "3. La partie restante est l'échantillon d'*apprentissage* pour l'estimation des paramètres des modèles.\n",
    "\n",
    "4. Pour chacune des méthodes, optimiser la complexité des modèles en minimisant une estimation \"sans biais\" de l'erreur de prévision, par exemple par [*validation croisée*](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf).\n",
    "    - Variables et interactions à prendre en compte dans la régression linéaire ou logistique;\n",
    "    - variables et méthode pour l'analyse discriminante;\n",
    "    - nombre de feuilles dans l'arbre de régression ou de classification;\n",
    "    - architecture (nombre de neurones, pénalisation) du perceptron;\n",
    "    - algorithme d'agrégation, \n",
    "    - noyau et pénalisation des SVMs.\n",
    "    \n",
    "5.  Comparaison des qualités de prévision sur la base du taux de mal classés pour le seul échantillon test qui est resté à l'écart de tout effort ou \"acharnement\" pour l'optimisation des modèles.\n",
    "\n",
    "**Remarques**\n",
    "\n",
    "* Lorsque vous disposez d'un petit volume de données, il est recommandé d'utiliser des procédures de validation adaptées afin de réduire la variance (moyenne) des estimations des erreurs de prévision. Nous utiliserons la [validation croisée](https://fr.wikipedia.org/wiki/Validation_croisée) dans le cadre de cette étude. Vous trouverez les détails de cette procédure à la fin de ce cahier.\n",
    "\n",
    "* Le critère utilisé lors de la validation dépend du problème: erreur quadratique, taux de mauvais classement, AUC (aire sous la courbe ROC), indice de Pierce, *log loss function*..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extraction des échantillons apprentissage et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des données pour l'apprentissage. \n",
    "\n",
    "**Q** Pourquoi les variables qualitatives sont-elles transformées en paquets d'indicatrices ou *dummy variables*?\n",
    "\n",
    "**Q** Pourquoi le type data frame est transformé en une matrice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables explicatives\n",
    "df = pd.get_dummies(df, columns = [\"JOUR\", \"STATION\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.135289Z",
     "start_time": "2019-10-28T10:26:55.128353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variable cible au format booléen:\n",
    "y_binary = df[\"dep_seuil\"].copy()\n",
    "\n",
    "# Variable cible au format continu:\n",
    "y = df[\"O3obs\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les variables i.e O3obs et dep_seuil du dataframe car nous ne devons pas utiliser les variables\n",
    "# cibles pour entrainer les algorithmes. Nous stockerons la variable O3obs pour l'étudier ensuite.\n",
    "df = df.drop([\"JOUR_0\", \"dep_seuil\", \"O3obs\"], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.361768Z",
     "start_time": "2019-10-28T10:26:55.143864Z"
    }
   },
   "outputs": [],
   "source": [
    "y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractions des échantillons d'apprentissage  et test pour les deux types de modèles. Comme le générateur est initalisé de façon identique, ce sont les mêmes échantillons dans les deux cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.374203Z",
     "start_time": "2019-10-28T10:26:55.364438Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    df, \n",
    "    y_binary, \n",
    "    test_size = 200, \n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "y_train = y.loc[y_binary_train.index]\n",
    "y_test  = y.loc[y_binary_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étape suivante est une étape de standardisation des données ou normalisation. Les variables sont divisées par leur écart-type. Ce n'est pas utile dans le cas d'un modèle linéaire élémentaire car la solution est identique mais indispensbale pour beaucoup d'autres méthodes non linéaires (SVM, réseaux de neurones, modèles avec pénalisation). Cette étape est donc concrètement systématiquement excéutée pour éviter des soucis. *Attention*, les mêmes paramètres  (moyennes, écarts-types) estimés sur l'échantillon d'apprentissage sont utilisés pour normaliser l'échantillon test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(pd.concat([X_train, X_test], axis = 'rows')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est préférable de centrer et de réduire les données lors de l'utilisation de modèles tels que les réseaux de neurones et les modèles linéaires. La réduction de l'échelle des variables facilitera la convergence du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.385746Z",
     "start_time": "2019-10-28T10:26:55.376347Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(\n",
    "    scaler.transform(X_train), \n",
    "    columns = df.columns, \n",
    "    index = X_train.index\n",
    ") \n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test), \n",
    "    columns = df.columns, \n",
    "    index = X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modèles linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les variables ne contribuent pas à expliquer la cible `O3obs`. Pour réduire le bruit du modèle, nous utilisons des méthodes de sélection de variables et tentons de retirer les variables qui n'apportent pas d'information. Un moyen efficace d'identifier les variables qui n'aident pas à modéliser notre variable cible est d'utiliser la régularisation.\n",
    "\n",
    "Nous utilisons la [pénalisation Lasso](http://wikistat.fr/pdf/st-m-app-select.pdf) dans le cadre de cette exemple. Nous pourrions aussi `retirer / ajouter` successivement les variables afin de mesurer leur contribution à la modélisation de la variable cible.\n",
    "\n",
    "**Q** Quel autre type de pénalisation est aussi utilisée en régression?\n",
    "\n",
    "**Q** Quelle la méthode qui combine les deux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A titre de comparaison, on trace la prévision de la concentration de l'échantillon test par la seule valeur du modèle *Mocage* ainsi que les résidus à ce modèle fonction de la valeur prédite (Mocage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.656598Z",
     "start_time": "2019-10-28T10:26:55.387384Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train[\"MOCAGE\"], y_train, \"o\")\n",
    "plt.xlabel(\"Mocage\")\n",
    "plt.ylabel(\"O3 observee\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.664342Z",
     "start_time": "2019-10-28T10:26:55.658583Z"
    }
   },
   "outputs": [],
   "source": [
    "f\"R2 Score: {r2_score(y_train,X_train['MOCAGE'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:55.829606Z",
     "start_time": "2019-10-28T10:26:55.666925Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"MOCAGE\"], y, \"o\")\n",
    "plt.xlabel(\"Mocage\")\n",
    "plt.ylabel(\"O3 observee\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:56.017898Z",
     "start_time": "2019-10-28T10:26:55.832030Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"MOCAGE\"], df[\"MOCAGE\"] - y, \"o\")\n",
    "plt.xlabel(\"Mocage\")\n",
    "plt.ylabel(\"Residus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter la qualité de ces résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:56.024237Z",
     "start_time": "2019-10-28T10:26:56.020078Z"
    }
   },
   "outputs": [],
   "source": [
    "f\"Erreur quadratique moyenne: {mean_squared_error(df['MOCAGE'], y)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:56.031419Z",
     "start_time": "2019-10-28T10:26:56.026125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Le coefficient de détermination \n",
    "# peut être négatif en prévision avec un mauvais modèle, \n",
    "# est nul si la prévision est constante égale à la moyennne\n",
    "f\"R2 score: {r2_score(df['MOCAGE'], y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Régression linéaire](http://wikistat.fr/pdf/st-m-app-select.pdf) ou modèle gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer cette prévision déterministe (équation de Navier et Stockes) par l'adaptation statistique la plus élémentaire. Il s'agit d'une régression avec choix de modèle par régularisation avec une pénalisation lasso. \n",
    "\n",
    "**Question:** Quelles est la valeur par défaut du paramètre de pénalisation Lasso?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:56.040356Z",
     "start_time": "2019-10-28T10:26:56.033529Z"
    }
   },
   "outputs": [],
   "source": [
    "model = linear_model.Lasso()\n",
    "model.fit(X_train,y_train)\n",
    "f\"Erreur quadratique moyenne: {mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:56.046880Z",
     "start_time": "2019-10-28T10:26:56.042637Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R2=\",r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre de pénalisation lasso est optimisé par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.159363Z",
     "start_time": "2019-10-28T10:26:56.048742Z"
    }
   },
   "outputs": [],
   "source": [
    "# grille de valeurs du paramètre alpha à optimiser\n",
    "grid =[{\"alpha\":[0.05,0.1,0.2,0.3,0.4,0.5,1]}]\n",
    "\n",
    "model = GridSearchCV(linear_model.Lasso(), grid, cv = 5)\n",
    "\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# paramètre optimal\n",
    "model.best_params_[\"alpha\"]\n",
    "\n",
    "f\"Meilleur R2 = {model.best_score_}, Meilleur paramètre = {model.best_params_}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle validation croisée est exécutée?\n",
    "\n",
    "Prévision avec la valeur optimale de `alpha` puis calcul et tracé des résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.174438Z",
     "start_time": "2019-10-28T10:26:58.162121Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test):4f}\")\n",
    "print(f\"R2 : {r2_score(y_test, y_pred):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.358260Z",
     "start_time": "2019-10-28T10:26:58.178213Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y_pred, y_test,\"o\")\n",
    "plt.xlabel(u\"O3 Prédite\")\n",
    "plt.ylabel(\"O3 observee\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.509798Z",
     "start_time": "2019-10-28T10:26:58.360558Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y_pred, y_test - y_pred,\"o\")\n",
    "plt.xlabel(u\"Prédites\")\n",
    "plt.ylabel(u\"Résidus\")\n",
    "plt.hlines(0,40,220)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comparer ces résidus avec ceux précédents (mocage) et noter l'amélioration. \n",
    "\n",
    "**Q** Commenter la forme du nuage et donc la validité du modèle. \n",
    "\n",
    "L'interprétation nécessite de connaître les valeurs des coefficients du modèle alors que l'objet `regLassOpt` issu de `GridSearchCV` ne retient pas les paramètres estimés. Il faut donc le ré-estimer avec la valeur optimale du paramètre de pénalisation si l'on souhaite afficher ces coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.519850Z",
     "start_time": "2019-10-28T10:26:58.511759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "model = linear_model.Lasso(alpha=model.best_params_['alpha'])\n",
    "model = model.fit(X_train, y_train)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.528471Z",
     "start_time": "2019-10-28T10:26:58.522068Z"
    }
   },
   "outputs": [],
   "source": [
    "coef = pd.Series(model.coef_, index = X_train.columns)\n",
    "print(\"Lasso conserve \" + str(sum(coef != 0)) + \n",
    "      \" variables et en supprime \" +  str(sum(coef == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.735083Z",
     "start_time": "2019-10-28T10:26:58.531014Z"
    }
   },
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(u\"Coefficients du modèle lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Noter les conséquences de la pénalisation; interpréter l'effet de chaque variable sur la concentration en ozone.\n",
    "\n",
    "Note: Il serait intéressant de compléter ces résultats avec les p-valeurs qui ne sont pas fournies par Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphe quivant permet d'identifier les bonnes et mauvaises prévisions de dépassement du seuil légal, ici fixé à $ 150 \\mu g $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.882749Z",
     "start_time": "2019-10-28T10:26:58.739066Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y_pred, y_test,\"o\")\n",
    "plt.xlabel(u\"Valeurs prédites\")\n",
    "plt.ylabel(u\"O3 observée\")\n",
    "plt.hlines(150,50,300)\n",
    "plt.vlines(150,0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:58.902637Z",
     "start_time": "2019-10-28T10:26:58.884695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dénombrement des erreurs par\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(y_pred>150, y_test>150)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Observer l'asymétrie de cette matrice. A quoi est-elle due au moins en partie ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scikit-learn* propose d'autres procédures d'optimisation du paramètre de régularisation lasso par validation croisée en régression; `lassoCV` utilise un algorithme de *coordinate descent*, sans calcul de dérivée puisque la norme *l1* n'est pas dérivable, tandis que `lassoLarsCV` est basée sur l'algorithme de *least angle regression*. Ces fonctions permettent de tracer également les *chemins de régularisation*. Voici l'exemple de `lassoCV` qui offre plus d'options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.289006Z",
     "start_time": "2019-10-28T10:26:58.904254Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LassoCV(\n",
    "    cv = 5, \n",
    "    alphas = np.array(range(1,50,1)) / 20.,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_log_alphas = - np.log10(model.alphas_)\n",
    "\n",
    "plt.figure()\n",
    "# ymin, ymax = 2300, 3800\n",
    "plt.plot(m_log_alphas, model.mse_path_, ':')\n",
    "plt.plot(m_log_alphas, model.mse_path_.mean(axis=-1), 'k',\n",
    "         label='MSE moyen', linewidth=2)\n",
    "plt.axvline(-np.log10(model.alpha_), linestyle='--', color='k',\n",
    "            label='alpha: optimal par VC')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('-log(alpha)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE de chaque validation: coordinate descent ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Vérifier que c'est bien la même valeur optimale que celle précédemment trouvée.\n",
    "\n",
    "Tracés des chemins de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.linear_model import lasso_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.520237Z",
     "start_time": "2019-10-28T10:26:59.290930Z"
    }
   },
   "outputs": [],
   "source": [
    "alphas_lasso, coefs_lasso, _ = lasso_path(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    alphas = np.array(range(1,50,1))/20.,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "styles = cycle(['-', '--', '-.', ':'])\n",
    "\n",
    "neg_log_alphas_lasso = - np.log10(alphas_lasso)\n",
    "\n",
    "for coef_l, s in zip(coefs_lasso, styles):\n",
    "    \n",
    "    l1 = plt.plot(neg_log_alphas_lasso, coef_l, linestyle=s, c='b')\n",
    "                  \n",
    "plt.xlabel('-Log(alpha)')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf) ou modèle binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même démarche est déroulée mais en modélisant directement la variable binaire Yb de dépassement ou non du seuil. Il s'agit d'une régression logistique avec toujours une pénalisation Lasso pour opérer une sélection de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.525714Z",
     "start_time": "2019-10-28T10:26:59.521881Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.769573Z",
     "start_time": "2019-10-28T10:26:59.527455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimisation du paramètre de pénalisation\n",
    "# grille de valeurs\n",
    "\n",
    "grid = [\n",
    "    {\"C\":[1,1.2,1.5,1.7,2,3,4]}\n",
    "]\n",
    "\n",
    "logistic_regression = GridSearchCV(\n",
    "    LogisticRegression(penalty=\"l1\",solver='liblinear'), \n",
    "    grid, \n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "logistic_regression = logistic_regression.fit(X_train, y_binary_train) \n",
    "\n",
    "f\"Meilleur score: {1. - logistic_regression.best_score_}, meilleur paramètre: {logistic_regression.best_params_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.777245Z",
     "start_time": "2019-10-28T10:26:59.771731Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur sur l'échantillon test\n",
    "1 - logistic_regression.score(X_test, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"optimal\"  obtenu est utilisé pour prédire l'échantillon test et estimer ainsi, sans biais, une erreur de prévision. \n",
    "\n",
    "La matrice de confusion croise les dépassements de seuils prédits avec ceux effectivement observés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.801370Z",
     "start_time": "2019-10-28T10:26:59.779803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prédiction\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'interprétation du modèle est basée sur les valeurs des coefficients avec les mêmes difficultés ou restrictions que pour la régression. Attention, `GridSearch` ne retient pas les coefficients, il faut les ré-estimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.818196Z",
     "start_time": "2019-10-28T10:26:59.804159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "logistic_regression = LogisticRegression(\n",
    "    penalty = \"l1\",\n",
    "    solver = 'liblinear',\n",
    "    C = logistic_regression.best_params_['C']\n",
    ")\n",
    "\n",
    "coef = logistic_regression.fit(X_train, y_binary_train).coef_\n",
    "\n",
    "coef = pd.Series(coef[0], index = X_train.columns).sort_values()\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:26:59.829411Z",
     "start_time": "2019-10-28T10:26:59.821565Z"
    }
   },
   "outputs": [],
   "source": [
    "f\"Lasso conserve {sum(coef != 0)} variables et en supprime {sum(coef == 0)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.067313Z",
     "start_time": "2019-10-28T10:26:59.834681Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "coef.plot(kind = \"barh\")\n",
    "\n",
    "plt.title(u\"Coefficients du modèle lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Interpréter l'effet des variables retenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.256807Z",
     "start_time": "2019-10-28T10:27:00.069887Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(\n",
    "    penalty = \"l1\",\n",
    "    solver = 'liblinear',\n",
    "    C = 3,\n",
    ")\n",
    "\n",
    "logistic_regression = logistic_regression.fit(X_train, y_binary_train)\n",
    "\n",
    "y_pred = logistic_regression.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_binary_test, y_pred[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr, lw=1)\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter la courbe ROC à propos du choix de la valeur seuil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 [K plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un cas d'application d'analyses discriminantes [non paramétriques](http://scikit-learn.org/stable/modules/neighbors.html), celles [paramétriques](http://scikit-learn.org/stable/modules/lda_qda.html) (gaussienes) linéaires et quadratiques sont également présentes dans *scikit-learn* mais laissées en exercice.\n",
    "\n",
    "Le paramètre de compléxité ($k$) est optimisé sur une grille prédéfinie en minimisant l'erreur estimée par validation croisée; scikit-learn propose de nombreuses options de validation croisée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.649692Z",
     "start_time": "2019-10-28T10:27:00.259022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimisation de k\n",
    "# grille de valeurs\n",
    "grid = [{\"n_neighbors\":list(range(1,15))}]\n",
    "\n",
    "knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid,\n",
    "    cv = 5,\n",
    ")\n",
    "\n",
    "knn = knn.fit(X_train, y_binary_train) \n",
    "\n",
    "# paramètre optimal\n",
    "knn.best_params_[\"n_neighbors\"]\n",
    "\n",
    "f\"Meilleur score = {1.- knn.best_score_:f}, meilleur paramètre: {knn.best_params_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.667716Z",
     "start_time": "2019-10-28T10:27:00.651522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision sur l'échantillon test\n",
    "1 - knn.score(X_test, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.707480Z",
     "start_time": "2019-10-28T10:27:00.670129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Compléter les résultats en utilisant la fonction [KNeighborsRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) pour modéliser la concentration; optimiser $k$, calculer la prévision de l'échantillon test, tracer le graphe des résidus, calculer le MSE sur l'échantillon test.\n",
    "\n",
    "# <FONT COLOR=\"Green\">Compléments: Méthodes d'Apprentissage </font> du [Module d'Immersion](https://github.com/Certificat-sciences-des-donnees-bigdata/Module-immersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. [Arbre binaire de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les [arbres binaires de décision](http://scikit-learn.org/stable/modules/tree.html) : discrimination ou régression, sont bien implémentés dans *scikit-learn* mais avec une insuffisance pour leur élagage. Ce n'est pas une *pénalisation* de la *complexité*, et donc précisément le nombre de feuilles qui est optimisé, mais la profondeur globale de l'arbre au risque d'élaguer, à une profondeur donnée, des feuilles importantes ou de conserver des feuilles ambigües.\n",
    "\n",
    "Comme précédemment, la validation croisée permet d'optimiser le paramètre sur une grille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.915612Z",
     "start_time": "2019-10-28T10:27:00.709662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimisation de la profondeur de l'arbre\n",
    "grid = [{\"max_depth\":list(range(2,10))}]\n",
    "\n",
    "decision_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(), \n",
    "    grid,\n",
    "    cv = 10,\n",
    ")\n",
    "\n",
    "decision_tree = decision_tree.fit(X_train, y_binary_train)\n",
    "\n",
    "# paramètre optimal\n",
    "f\"Meilleur score = {1. - decision_tree.best_score_:f}, meilleur paramètre: {decision_tree.best_params_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.937480Z",
     "start_time": "2019-10-28T10:27:00.918470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision\n",
    "1 - decision_tree.score(X_test, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:00.962314Z",
     "start_time": "2019-10-28T10:27:00.942018Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autre difficulté dans la représentation d'un arbre de décision binaire. Le logiciel conseillé (Graphviz) semble délicat d'installation et d'utilisation pour un néophyte. Il est possible de lister la construction des noeuds avec quelques [lignes de commande.](http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(\n",
    "    max_depth = decision_tree.best_params_['max_depth']\n",
    ")\n",
    "\n",
    "decision_tree.fit(X_train, y_binary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "_ = tree.plot_tree(decision_tree, feature_names = X_train.columns, fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de l'interprétation de l'arbre? Comparer les rôles des variables avec le modèle logit.\n",
    "\n",
    "**Exercice** Compléter les résultats en utilisant la fonction [DecisionTreeRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) pour modéliser concentration; optimiser la profondeur, calculer la prévision de l'échantillon test, tracer les résidus, calculer le MSE sur l'échantillon test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 [Réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux neuronaux (perceptron multicouche) ne sont présents dans le package `Scikit-learn` qu'à partir de la version 0.18. Les méthodes *profondes* (*deep learning*) nécessitent l'installation des librairies [*theano*](http://deeplearning.net/software/theano/) et [*Lasagne*](http://lasagne.readthedocs.io/en/latest/index.html) ou [*theano*](http://deeplearning.net/software/theano/), [*TensorFlow*](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html) et [*Keras*](https://keras.io/). Ces dernières sont nettement plus complexes à installer, surtout sous Windows. Elles feront l'objet d'un autre tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:01.126857Z",
     "start_time": "2019-10-28T10:27:01.114373Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des paramètres dont le nombre de neurones et `alpha` qui règle la régularisation par défaut 10-5. Le nombre de neurones est optimisé mais ce peut être `alpha` avec un nombre grand de neurones. Le nombre max d'itérations par défaut (200) semble insuffisant. Il est fixé à 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:14.258429Z",
     "start_time": "2019-10-28T10:27:01.128767Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = [{\"hidden_layer_sizes\":list([(5,),(6,),(7,),(8,)])}]\n",
    "\n",
    "neural_network = GridSearchCV(\n",
    "    MLPClassifier(max_iter=1000, warm_start=True, random_state=42),\n",
    "    grid,\n",
    "    cv = 10,\n",
    ")\n",
    "\n",
    "neural_network = neural_network.fit(X_train, y_binary_train)\n",
    "\n",
    "# paramètre optimal\n",
    "f\"Meilleur score = {1.- neural_network.best_score_:f}, meilleur paramètre: {neural_network.best_params_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:14.268771Z",
     "start_time": "2019-10-28T10:27:14.260481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision sur le test\n",
    "1 - neural_network.score(X_test, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:14.296148Z",
     "start_time": "2019-10-28T10:27:14.270747Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "y_pred = neural_network.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Remplacer ensuite la fonction MLPClassifier par celle [MLPRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) de régression. Optimiser le paramètre, calculer la prévision, les résidus, le MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 [Forêts aléatoires](http://wikistat.fr/pdf/st-m-app-agreg.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie *randomForest* de R utilise le programme historique développé par [Breiman et Cutler](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_software.htm)(2001) et interfacé  par [Liaw et Wiener](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf). Cette interface est toujours mise à jour mais il n'est pas sûr que le programme original continue d'évoluer depuis 2004. Pour des tailles importantes d'échantillons, quelques milliers, cette implémentation atteint des temps d'exécution rédhibitoires (cf. cet [exemple](https://github.com/wikistat/Ateliers-Big-Data/blob/master/2-MNIST/Atelier-MNIST-R.ipynb)) au contraire de celle en Python dont gestion mémoire et capacité de parallélisation ont été finement optimisées par [Louppe et al.](http://fr.slideshare.net/glouppe/accelerating-random-forests-in-scikitlearn)(2014). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même que le boosting, deux fonctions  de forêt sont proposés dans [scikit-learn](http://scikit-learn.org/stable/modules/ensemble.html) ; une pour la régression et une pour la classification ainsi qu'une version \"plus aléatoire\". Par rapport à la version originale de R, moins d'options sont proposées mais l'utilisation de base est très similaire avec le même jeu de paramètres.\n",
    "\n",
    "**Q** Identifier les paramètres, les valeurs par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:14.899810Z",
     "start_time": "2019-10-28T10:27:14.298697Z"
    }
   },
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators = 500,\n",
    "    criterion = 'gini', \n",
    "    max_depth = None,\n",
    "    min_samples_split = 2, \n",
    "    min_samples_leaf = 1, \n",
    "    max_features = 'auto', \n",
    "    max_leaf_nodes = None,\n",
    "    bootstrap = True, \n",
    "    oob_score = True\n",
    ")\n",
    "# apprentissage\n",
    "random_forest = random_forest.fit(X_train,y_binary_train)\n",
    "\n",
    "1 - random_forest.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer l'erreur out-of-bag ci-dessus avec celle sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:14.948840Z",
     "start_time": "2019-10-28T10:27:14.901910Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - random_forest.score(X_test,y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation par validation croisée du nombre de variables tirés aléatoirement lors de la construction de chaque noeud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:17.404805Z",
     "start_time": "2019-10-28T10:27:14.950533Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = [{\"max_features\":list(range(2,10,1))}]\n",
    "\n",
    "random_forest = GridSearchCV(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    grid,\n",
    "    cv = 5,\n",
    ")\n",
    "\n",
    "random_forest = random_forest.fit(X_train, y_binary_train)\n",
    "\n",
    "# paramètre optimal\n",
    "f\"Meilleur score: {1. - random_forest.best_score_:f}, meilleur paramètre: {random_forest.best_params_}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs exécutions, rendues aléatoires par la validation croisée, peuvent conduire à des valeurs \"optimales\" différentes de ce paramètre sans pour autant nuire à la qualité de prévision sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:17.423387Z",
     "start_time": "2019-10-28T10:27:17.406570Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - random_forest.score(X_test,y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Tester différentes valeurs de *min_samples_split* de celle trouvée optimale. Conclusion sur la sensibilité de l'optimisation de ce paramètre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:17.486246Z",
     "start_time": "2019-10-28T10:27:17.425288Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme avec R, il est possible de calculer un indicateur d'importance des variables pour aider à une forme d'interprétation. Celui-ci dépend de la position de la variable dans l'arbre et correspond donc au *mean decrease in Gini index* de R plutôt qu'au *mean descrease in accuracy*. La forêt doit être réestimée car GridSearch ne connaît pas le paramètre d'importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:17.615311Z",
     "start_time": "2019-10-28T10:27:17.487970Z"
    }
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100,max_features=2)\n",
    "random_forest = random_forest.fit(X_train, y_binary_train)\n",
    "\n",
    "# Importance des variables\n",
    "importances = pd.DataFrame(\n",
    "    random_forest.feature_importances_, \n",
    "    index = X_train.columns, \n",
    "    columns = [\"importance\"]\n",
    ").sort_values(ascending = False, by = \"importance\")\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comparer les importances des variables et les sélections opérées précédemment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Remplacer ensuite la fonction RandomForestClassifier par celle [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) de régression. Optimiser le paramètre, calculer la prévision, les résidus, le MSE.\n",
    "\n",
    "**Exercice** Expérimenter également le boosting sur ces données en exécutant la fonction [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier) opérant l'agorithme de *gradient tree boosting*. \n",
    "\n",
    "**Remarque:** Une version \"améliorée\" de *boosting* mieux paralélisée et incluant d'autres paramètres (pénalisation), est  proposé dans le package: [`XGBoost`](https://xgboost.readthedocs.io/en/latest/build.html#python-package-installation) qui peut être utilisé à partir de Python mais aussi R, Julia ou Java. Nénamoins le choix est fait d'arrêter l'acharnement sur ces données; `XGBoost` est testé en python sur un autre jeu de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 [*Support Vector Machine*](http://wikistat.fr/pdf/st-m-app-svm.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreux paramètres sont associés à cette méthode. La liste est à consulter dans la [documentation](http://scikit-learn.org/stable/modules/svm.html) en ligne.\n",
    "\n",
    "L'optimisation de la pénalisation (paramètre C) est recherchée sur une grille par validation croisée. Remarque: il serait nécessaire d'optimiser également la valeur du coefficient *gamma* lié au noyau gaussien (\"écart-type\").\n",
    "\n",
    "Il est souvent nécessqire de normaliser des données avant d'opérer les SVM mais cela ne semble pas nécessaire ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:18.138738Z",
     "start_time": "2019-10-28T10:27:17.776821Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = [{\"C\":[0.4,0.5,0.6,0.8,1,1.4]}]\n",
    "\n",
    "svm = GridSearchCV(\n",
    "    SVC(random_state = 42),\n",
    "    grid,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "svm = svm.fit(X_train, y_binary_train)\n",
    "\n",
    "# paramètre optimal\n",
    "f\"Meilleur score: {1.- svm.best_score_:f}, meilleur paramètre: {svm.best_params_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:18.147549Z",
     "start_time": "2019-10-28T10:27:18.140664Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1 - svm.score(X_test, y_binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:18.175776Z",
     "start_time": "2019-10-28T10:27:18.150195Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# matrice de confusion\n",
    "pd.crosstab(y_pred, y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Comme précédemment, remplacer ensuite la fonction SVC par celle [SVR](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) de régression. Optimiser le paramètre, calculer la prévision, les résidus; le MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Synthèse: comparaison des méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Courbes ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans toute méthode, la prévision de dépassement ou non est associée au choix d'un seuil qui est par défaut 0.5. L'optimisaiton de ce seuil dépend des coûts respectifs associés aux faux positifs et aux faux négatifs qui ne sont pas nécessairement égaux. La courbe ROC permet de représenter l'influence de ce seuil sur les taux de faux positifs et vrais positifs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:18.183812Z",
     "start_time": "2019-10-28T10:27:18.177974Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"random_forest\": random_forest,\n",
    "    \"neural_netork\": neural_network,\n",
    "    \"decision_tree\": decision_tree,\n",
    "    \"knn\": knn,\n",
    "    \"logistic_regression\": logistic_regression,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T10:27:34.432659Z",
     "start_time": "2019-10-28T10:27:18.185975Z"
    }
   },
   "outputs": [],
   "source": [
    "for method, model in methods.items():\n",
    "    \n",
    "    model = model.fit(X_train, y_binary_train)\n",
    "    \n",
    "    probas_ = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_binary_test, probas_[:,1])\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw = 1,label = method)\n",
    "    \n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22** Le critère d'AUC (aire sous la courbe) permet-il d'ordonner les courbes et donc les méthodes? \n",
    "\n",
    "C'est à un taux de faux positif admissible et donc à valeur de seuil fixé qu'il faut choisir la méthode d'apprentissage à privilégier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion sur l'apprentissage\n",
    "**Q** Comparer les qualités de prévision d'occurrence d'un pic d'ozone: MOCAGE *vs.* adaptation statistique\n",
    "\n",
    "**Q** Quel méthode d'apprentissage retenir en termes de qualité de prévision?\n",
    "\n",
    "**Q** Quel méthode d'apprentissage retenir pour un meilleur compromis prévision / interprétation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2 Zoom sur la validation croisée, Kfold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé la méthode `GridSearchCV` pour rechercher les meilleurs paramètres des différents modèles. La méthode `GridSearchCV` effectue une validation croisée pour chaque configuration de la grille de paramètres indiquée par l'utilisateur. \n",
    "\n",
    "La validation croisée permet d'évaluer le modèle sur l'ensemble des données. Le meilleur modèle est celui qui, en moyenne, généralise le mieux sur les données de validation. \n",
    "\n",
    "Pour effectuer une validation croisée, le jeu de données doit être divisé en `k` parties (k folds) de taille identique. Ensuite, nous devons entraîner le modèle sur `k-1` parties des données et valider le modèle sur la partie que l'on a exclu de l'entrainement. Il faut répéter l'opération `k` fois de façons à évaluer le modèle sur l'ensemble des `k` parties du dataset. Il est parfois utile de mélanger les données avant de construire les plis de validation. \n",
    "\n",
    "Si nous décidons d'effectuer une validation croisée à 5 plis, nous devrons définir les différents plis du dataset qui contiendront chacun 20% des données :\n",
    "\n",
    "<table style=\"border-collapse:collapse;border-spacing:0\" class=\"tg\"><thead><tr><th style=\"background-color:#ffccc9;border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Fold 1 (20% observations)</th></tr></thead><tbody><tr><td style=\"background-color:#ffce93;border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Fold 2 <span style=\"font-weight:normal;font-style:normal;text-decoration:none\">(20% observations)</span></td></tr><tr><td style=\"background-color:#fffc9e;border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Fold 3 <span style=\"font-weight:normal;font-style:normal;text-decoration:none\">(20% observations)</span></td></tr><tr><td style=\"background-color:#9aff99;border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Fold 4 <span style=\"font-weight:normal;font-style:normal;text-decoration:none\">(20% observations)</span></td></tr><tr><td style=\"background-color:#96fffb;border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal\">Fold 5 <span style=\"font-weight:normal;font-style:normal;text-decoration:none\">(20% observations)</span></td></tr></tbody></table>\n",
    "\n",
    "\n",
    "- Entrainer le modèle sur les parties 2, 3, 4, 5 et mesurer l'erreur `e1` sur la partie 1.\n",
    "\n",
    "- Entrainer le modèle sur les parties 1, 3, 4, 5 et mesurer l'erreur `e2` sur la partie 2.\n",
    "\n",
    "- Entrainer le modèle sur les parties 1, 2, 4, 5 et mesurer l'erreur `e3` sur la partie 3.\n",
    "\n",
    "- Entrainer le modèle sur les parties 1, 2, 3, 5 et mesurer l'erreur `e4` sur la partie 4.\n",
    "\n",
    "- Entrainer le modèle sur les parties 1, 2, 3, 4 et mesurer l'erreur `e5` sur la partie 5.\n",
    "\n",
    "L'erreur du modèle est égale à la moyenne des erreurs des plis de validation: `(e1 + e2 + e3 + e4 + e5) / 5`\n",
    "\n",
    "Si vous avez très peu de données, vous pouvez utiliser la validation croisée `leave-one-out`. C'est un cas particulier de la validation croisée où le nombre de plis `k` est égal au nombre d'observations dans le jeu de données. La méthode `leave-one-out` consiste à entraîner un modèle sur `n-1` observations et à le valider sur une seule observation du jeu de données. L'augmentation de la valeur de `k` est coûteuse en temps d'exécution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Intialisation du model\n",
    "model = RandomForestClassifier(max_depth = 20, n_estimators = 100)\n",
    "# model = LogisticRegression()\n",
    "# model = MLPClassifier(max_iter=10000, warm_start=True, random_state=42)\n",
    "\n",
    "# e1, e2, ...\n",
    "error = {}\n",
    "\n",
    "# Découpage du dataset en 5 parties, on mélange les données au préalable.\n",
    "kfold = model_selection.KFold(n_splits = 5,  shuffle = True)\n",
    "\n",
    "for split, (fit, val) in enumerate(kfold.split(X_train, y_binary_train)):\n",
    "    \n",
    "    # Sélection de l'ensemble des features\n",
    "    X_fit = X_train.iloc[fit]\n",
    "    X_val = X_train.iloc[val]\n",
    "    \n",
    "    # Sélection des variables cibles\n",
    "    y_fit = y_binary_train.iloc[fit]\n",
    "    y_val = y_binary_train.iloc[val]\n",
    "    \n",
    "    # Entrainement du modèle\n",
    "    model = model.fit(X_fit, y_fit)\n",
    "    \n",
    "    # Calcul de l'erreur\n",
    "    error[f\"split_{split}\"] = accuracy_score(\n",
    "        y_pred = model.predict(X_val), \n",
    "        y_true = y_val,\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy fold {split}: {error[f'split_{split}']:4f}\")\n",
    "\n",
    "print(f\"\\nAverage accuracy: {np.mean(list(error.values())):4f}, std: {np.std(list(error.values())):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrice de confusion\n",
    "pd.crosstab(model.predict(X_test), y_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "L'objectif de la validation est d'estimer l'erreur du modèle lorsqu'il sera appliqué sur le terrain, il est donc nécessaire de simuler au mieux l'environnement du modèle lors de son évaluation. La validation croisée n'est pas toujours la meilleure façon d'estimer cette erreur. Il existe de nombreuses alternatives à la validation croisée. Nous n'étudierons pas ces solutions dans ce cours mais vous pouvez trouver les différentes stratégies de validation sur le site de [sklearn](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "Une liste non exhaustive de stratégies de validation:\n",
    "\n",
    "- Validation croisée Monte Carlo\n",
    "- Validation croisée groupée\n",
    "- Validation croisée stratifiée\n",
    "- Validation temporelle\n",
    "- Validation progressive\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
